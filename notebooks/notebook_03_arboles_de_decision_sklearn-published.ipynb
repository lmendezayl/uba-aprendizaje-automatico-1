{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/aprendizaje-automatico-dc-uba-ar/material/blob/main/notebooks/notebook_03_arboles_de_decision_sklearn-published.ipynb)\n",
    "\n",
    "## Scikit-learn (sklearn)\n",
    "\n",
    "### Primera aplicación, clasificación de \"iris\"\n",
    "\n",
    "El dataset Fisher's Iris es un conjunto de datos multivariado introducido por Ronald Fisher en su paper de 1936 *The use of multiple measurements in taxonomic problems* como un ejemplo de análisis discriminante lineal.\n",
    "\n",
    "\n",
    "![Representación de las flores del data set](https://github.com/aprendizaje-automatico-dc-uba-ar/material/raw/main/notebooks/n03-iris.png)\n",
    "\n",
    "\n",
    "\n",
    "El conjunto de datos contiene 50 muestras de cada una de tres especies de Iris (Iris setosa, Iris virginica e Iris versicolor). Se midió cuatro rasgos de cada muestra: el largo y ancho del sépalo y pétalo, en centímetros y además se tiene el nombre de la especie a la que pertence. Basado en la combinación de estos cuatro rasgos, Fisher desarrolló un modelo discriminante lineal para distinguir entre una especie y otra."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de empezar, cargamos todas las bibliotecas que vamos a usar. Como iris es un dataset muy común, forma parte de los datasets que provee `sklearn`.\n",
    "\n",
    "\n",
    "Acá vemos como cargarlo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Cargamos algunas bibliotecas \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn \n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [10, 5] # para ver los gráficos más grandes\n",
    "\n",
    "# Cargamos el dataset que usaremos hoy\n",
    "from sklearn.datasets import load_iris\n",
    "iris_dataset = load_iris()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Antes de empezar: exploración del objeto ```iris_dataset```\n",
    "\n",
    "1. ¿Qué tipo de objeto es `iris_dataset`?\n",
    "1. Listar las claves que tiene.\n",
    "1. Listar los valores que puede tomar la variable `target` (las que vamos a querer aprender).\n",
    "1. Listar los atributos del dataset.\n",
    "1. ¿Qué hay en las primeras 5 filas?\n",
    "1. ¿Qué dimensión tiene el dataset?\n",
    "1. ¿Cuál es el `target` en las últimas 5 filas?\n",
    "\n",
    "Además, hay una descripción del dataset incluida en el objeto que se puede acceder con: `iris_dataset.DESCR`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Paso 1: División de datos (training - testing)\n",
    "\n",
    "Ya veremos en las próximas clases de la materia, pero una forma de mitigar la percepción de cuán bien (o mal) anda nuestro modelo, es separar nuestros datos en 2:\n",
    "\n",
    "  - una parte para mirar, entender y **entrenar**\n",
    "  - otra parte que solo usaremos para medir la performance\n",
    "\n",
    "(más detalles en breve)\n",
    "\n",
    "<img src=\"https://github.com/aprendizaje-automatico-dc-uba-ar/material/raw/main/notebooks/n03-train-test-split.png\"  width=\"600\">\n",
    "Fuente imagen: https://www.sharpsightlabs.com/blog/scikit-train_test_split/\n",
    "\n",
    "\n",
    "Para esto usaremos la función `train_test_split` de `sklearn` [(ver Documentación)](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) y generaremos:\n",
    "  - `X_train`: es una matriz con un subconjunto del dataset original con los atributos de las observaciones \n",
    "  - `y_train`: es un vector con la clase a la que corresponde cada instancia de `X_train` \n",
    "  - `X_test`: es el subconjunto restante del dataset original que no fue incluido en `X_train`\n",
    "  - `y_test`: es un vector con la clase a la que corresponde cada instancia de `X_test` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import sklearn.model_selection\n",
    "\n",
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(\n",
    "                    iris_dataset['data'], \n",
    "                    iris_dataset['target'], \n",
    "                    random_state=4, \n",
    "                    test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos verificar que los tamaños para ver que coinciden con lo previsto. Sugerencia: explorar los objetos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"X_train dimensión: {X_train.shape}\")\n",
    "print(f\"y_train dimensión: {y_train.shape}\")\n",
    "\n",
    "print(f\"X_test dimensión: {X_test.shape}\")\n",
    "print(f\"y_test dimensión: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pregunta** \n",
    "\n",
    "¿Qué orden tienen los datos en esta partición? ¿Preservan el mismo orden? *Hint* Ver documentación de `train_test_split`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Paso 2: Exploración de los datos\n",
    "\n",
    "Como vimos anteriormente, los datos se encuentran dentro de un _array_ de `numpy`. Podemos pasarlo a un dataframe de `pandas` para tener una mejor visualización.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "iris_dataframe = pd.DataFrame(X_train, columns=iris_dataset.feature_names)\n",
    "iris_dataframe.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de empezar a construir un clasificador, realicemos una breve exploración de los datos:\n",
    "\n",
    "1. ¿qué se ve en el siguiente gráfico?\n",
    "1. ¿cuántas clases hay?\n",
    "1. ¿qué variable (o pares de variables) parecen separar mejor a los datos?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "pd.plotting.scatter_matrix(iris_dataframe, c=y_train, s=80, figsize=(15, 8), alpha=.8);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Paso 3: Construcción de un modelo \n",
    "\n",
    "Para construir nuestro árbol creamos un objeto de la clase [`DecisionTreeClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html) a la que más tarde cambiaremos parámetros.\n",
    "\n",
    "En este punto definimos que:\n",
    "  - la profundidad máxima del árbol será 3\n",
    "  - que el criterio para la selección en cada nodo sera `entropy`\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "arbol = DecisionTreeClassifier(max_depth=3, criterion=\"entropy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez creado nuestro clasificador, debemos entrenarlo con el método `fit`. \n",
    "\n",
    "Es interesante mencionar que en `sklearn` siempre usaremos `fit()` para entrenar pasandole los datos. La configuración vendrá en el constructor.\n",
    "\n",
    "**Antes** de ejecutar `fit` explorar `arbol.fit?`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arbol.fit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "arbol.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Paso 4: Predicciones\n",
    "\n",
    "Si queremos predecir una nueva instancia, por ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "X_new = np.array([[5, 2.9, 1, 0.2]])\n",
    "print(f\"X_new.shape: {X_new.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Necesitamos contar con nuestro clasificador (previamente entrenado) e invocar a `predict` con la(s) instancia(s) que queremos predecir.\n",
    "\n",
    "**Antes** de ejecutar `predict` explorar `arbol.predict?`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arbol.predict?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "prediction = arbol.predict(X_new)\n",
    "print(f\"Predicción: {prediction}\")\n",
    "print(f\"Nombre de la clase predicha: {iris_dataset['target_names'][prediction]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Paso 5: Evaluación del modelo\n",
    "\n",
    "Ahora ya estamos listos para poder verificar la performance de nuestro árbol con los datos que habíamos separado para _test_ previamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# predecimos los valores para las instacias que no vimos\n",
    "y_pred = arbol.predict(X_test)\n",
    "\n",
    "print(f\"Predicciones:   {y_pred}\\nValores reales: {y_test}\")\n",
    "# Podemos calcular el accuracy (exactitud) comparando los valores predichos contra los reales, \n",
    "# para ello contamos cuántas coincidencias hubo y dividimos por la cantidad de comparaciones que hicimos:\n",
    "print(f\"Accuracy sobre el test set: {np.mean(y_pred == y_test)}\") \n",
    "\n",
    "#También podemos invocar al método score que viene con los DecisionTreeClassifier\n",
    "print(f\"Accuracy sobre el test set: {arbol.score(X_test, y_test)}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos observar el resultado de nuestra clasificación con las matrices de confusión que tienen:\n",
    "- cada fila los valores observados o reales\n",
    "- cada columna los valores predichos\n",
    "\n",
    "que si integramos esta información nos da:\n",
    "- $m_{i,i}$ las instancias bien clasificadas\n",
    "- $m_{i,j}\\ (con\\ i\\neq j)$ las instancias mal clasificadas\n",
    "\n",
    "Ej. si tenemos la siguiente matriz de confusión:\n",
    "\n",
    "||setosa|versicolor|virginica|\n",
    "|-----|-----|-----|-----|\n",
    "|**setosa**| 6 | 0 | 0 |\n",
    "|**versicolor**| 0 | 2 | 1 |\n",
    "|**virginica**| 0 | 0 | 6 | \n",
    "\n",
    "Podemos decir que todas las instancias de la clases **setosa** y **virginica** fueron correctamente clasificadas, mientras que para las de **versicolor** 2 fueron correctas, mientras que una fue clasificada con **virginica** fallando en este caso la predicción.\n",
    "\n",
    "Si sumamos por filas podemos ver que en _test_ tenemos: \n",
    "  - 6 de clase **setosa**\n",
    "  - 3 de clase **versicolor** \n",
    "  - 6 de clase **virginica**\n",
    "  \n",
    "Y si sumamos por columna podemos ver la cantidad predicha para cada clase:\n",
    "  - 6 de clase **setosa**\n",
    "  - 2 de clase **versicolor** \n",
    "  - 7 de clase **virginica**\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Matriz de confusión:\")\n",
    "confusion = sklearn.metrics.confusion_matrix(y_pred=y_pred, y_true=y_test)\n",
    "display(pd.DataFrame(confusion, columns=iris_dataset['target_names'], index=iris_dataset['target_names']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### En resumen\n",
    "\n",
    "1. separamos nuestro data set original en entrenamiento (_train_) y evaluación (_test_)\n",
    "1. armamos y entrenamos (`fit`) un árbol de decisión con parámetros:\n",
    "    - `max_depth=3`\n",
    "    - `criterion=\"entropy\"`\n",
    "1. evaluamos el árbol en el conjunto de entrenamiento y de evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(\n",
    "    iris_dataset['data'], iris_dataset['target'], random_state=4, test_size=0.1)\n",
    "\n",
    "arbol = DecisionTreeClassifier(max_depth=3, criterion=\"entropy\")\n",
    "arbol.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Score sobre el training set: {arbol.score(X_train, y_train):.2f} ¿qué indica este número?\")\n",
    "print(f\"Score sobre el test set: {arbol.score(X_test, y_test):.2f}  ¿qué indica este número?\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Experimentando con Árboles de Decisión: \n",
    "\n",
    "1. Probar distintos valores para: `max_depth` y graficar la performance (_accuracy_) sobre el conjunto de test al variar este parámetro. \n",
    "1. ¿Qué ocurre con la _accuracy_ sobre train con respecto al valor sobre test de un mismo clasificador? \n",
    "1. ¿Cuál es el máximo valor de profundidad que se alcanza?¿cómo lo obtengo?¿por qué? \n",
    "    Para responder estas pregunta se puede acceder a la documentación con el comando `sklearn.tree.DecisionTreeClassifier?`\n",
    "1. Graficar la importancia de features para el clasificador con mejor _Accuracy_ en el test_set. Explorar el atributo `feature_importances_` de un árbol entrenado, ¿qué atributos fueron los mas relevantes? ¿es el mismo método que el visto en clase?\n",
    "1. Evaluar la importancia de features utilizando `permutation_importance`, graficar.\n",
    "    \n",
    "1. Graficar el árbol obtenido (ver función `dibujar_arbol` provista en la próxima celda). \n",
    "\n",
    "    1. ¿qué representa cada nodo?\n",
    "    1. ¿qué información contiene cada nodo?\n",
    "    1. ¿qué representa el color?\n",
    "    1. ¿qué son los ejes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# !pip3 install pydotplus\n",
    "# También instalar Graphviz. (en ubuntu: sudo apt-get install graphviz)\n",
    "\n",
    "from six import StringIO  #pip3 install six\n",
    "##### from sklearn.externals.six import StringIO  # opción para versiones más viejas de sklearn\n",
    "from IPython.display import Image, display\n",
    "import pydotplus\n",
    "\n",
    "    \n",
    "def dibujar_arbol(clf, c_name=iris_dataset.target_names, f_name=iris_dataset.feature_names):\n",
    "    #\n",
    "    # modo de uso: dibujar_arbol(arbol)\n",
    "    #\n",
    "    dot_data = StringIO()\n",
    "    sklearn.tree.export_graphviz(clf, out_file = dot_data,  \n",
    "                    filled = True, \n",
    "                    class_names = c_name,\n",
    "                    feature_names = f_name,\n",
    "                    special_characters = True)\n",
    "\n",
    "    graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "    display(Image(graph.create_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sobre fronteras de decisión\n",
    "\n",
    "A continuación exploraremos dentro del dataset iris el funcionamiento de las fronteras de decisión.\n",
    "Para hacerlo nos quedaremos sólo con 2 dimensiones del dataset: `sepal length (cm)`, `sepal width (cm)`.\n",
    "\n",
    "En la próxima celda tenemos la función `explore_decision_tree_boundaries` que si es llamada sin parámetros corre un árbol de clasificación con los parámetros por defecto del mismo y genera una representación de como el plano conformado por las 2 dimensiones propuesta se dividen en las clases que predecirán y árbol que generó dichas fronteras.\n",
    "\n",
    "Explorar diversos valores permitidos de profundidad máxima permitido del árbol del clasificador y analizar las visualizaciones generadas en términos de: \n",
    "  - sobreajuste\n",
    "  - subajuste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "\n",
    "def explore_decision_tree_boundaries(max_depth=None, criterion=\"entropy\", data_set=iris_dataset, cols=[0, 1]):\n",
    "    n_classes, plot_colors, plot_step = 3, \"ryb\", 0.02\n",
    "    fig=plt.figure(figsize=(10,7), dpi= 100, facecolor='w', edgecolor='k')\n",
    "    \n",
    "    X = data_set[\"data\"][:, cols]\n",
    "    y = data_set[\"target\"]\n",
    "\n",
    "    # Build and train Classifier\n",
    "    tree = DecisionTreeClassifier(max_depth=max_depth, criterion=criterion).fit(X, y)\n",
    "\n",
    "    # Plot the decision boundary\n",
    "    ax = plt.subplot(1, 1, 1)\n",
    "    plt.tight_layout(h_pad=0.5, w_pad=0.5, pad=2.5)\n",
    "    DecisionBoundaryDisplay.from_estimator(\n",
    "        tree,\n",
    "        X,\n",
    "        cmap=plt.cm.RdYlBu,\n",
    "        response_method=\"predict\",\n",
    "        ax=ax,\n",
    "        xlabel=data_set.feature_names[cols[0]],\n",
    "        ylabel=data_set.feature_names[cols[1]],\n",
    "    )\n",
    "\n",
    "    # Plot the training points\n",
    "    for i, color in zip(range(n_classes), plot_colors):\n",
    "        idx = np.where(y == i)\n",
    "        plt.scatter(\n",
    "            X[idx, 0],\n",
    "            X[idx, 1],\n",
    "            c=color,\n",
    "            label=data_set.target_names[i],\n",
    "            cmap=plt.cm.RdYlBu,\n",
    "            edgecolor=\"black\",\n",
    "            s=15,\n",
    "        )\n",
    "\n",
    "    plt.suptitle(f\"Fronteras de decisión de un árbol de altura {tree.get_depth()} y #hojas: {tree.get_n_leaves()}\")\n",
    "    plt.legend(loc=\"lower right\", borderpad=0, handletextpad=0)\n",
    "    _ = plt.axis(\"tight\")\n",
    "    plt.show()\n",
    "    \n",
    "    dibujar_arbol(tree, f_name=[data_set.feature_names[cols[0]],data_set.feature_names[cols[1]]]\n",
    "                 )\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejecutar la función y luego explorar como cambia el comportamiento al modificar los parámetros por defecto:\n",
    "  - `max_depth`\n",
    "  - `criterion`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explore_decision_tree_boundaries()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
